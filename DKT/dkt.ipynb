{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import math\n",
    "from tqdm import tqdm"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "source": [
    "data = pd.read_csv('test_2.csv') # fill with data file"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "vocab_size = data['problem_id'].nunique() + 1  # Number of unique problem IDs\n",
    "max_seq_len = 500  # Set maximum sequence length\n",
    "\n",
    "data = data[['user_id', 'problem_id', 'skill_id', 'correct', 'order_id']]\n",
    "data = data.sort_values(by=['user_id', 'order_id'])\n",
    "data = data.fillna(0)  # Fill missing values with 0 for now\n",
    "\n",
    "le = LabelEncoder()\n",
    "data['encoded_problem_id'] = le.fit_transform(data['problem_id'])\n",
    "\n",
    "grouped = data.groupby('user_id')\n",
    "\n",
    "seq = []\n",
    "lab = []\n",
    "\n",
    "for user, group in tqdm(grouped):\n",
    "    group = group.sort_values(by='order_id')\n",
    "    feature_seq = group['encoded_problem_id'].to_numpy()\n",
    "    correct_seq = group['correct'].to_numpy()\n",
    "\n",
    "    for start_idx in range(0, len(feature_seq), max_seq_len):\n",
    "        end_idx = min(start_idx + max_seq_len, len(feature_seq))\n",
    "\n",
    "        # Get subsequence for this user\n",
    "        sub_feature_seq = feature_seq[start_idx:end_idx]\n",
    "        sub_correct_seq = correct_seq[start_idx:end_idx]\n",
    "\n",
    "        # Pad feature sequence to max_seq_len\n",
    "        padded_feature_seq = F.pad(torch.tensor(sub_feature_seq, dtype=torch.float32),\n",
    "                                   (0, max_seq_len - len(sub_feature_seq)),\n",
    "                                   value=-1)\n",
    "        seq.append(padded_feature_seq)\n",
    "\n",
    "        # Pad label sequence with shape [timesteps, vocab_size]\n",
    "        blank_labels = np.full((max_seq_len, vocab_size), -1, dtype=np.float32)\n",
    "        blank_labels[:len(sub_feature_seq), sub_feature_seq] = sub_correct_seq\n",
    "\n",
    "        lab.append(torch.tensor(blank_labels, dtype=torch.float32))\n",
    "\n",
    "# Convert seq and lab to tensors\n",
    "seq = torch.stack(seq)\n",
    "lab = torch.stack(lab)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(seq.shape)\n",
    "print(lab.shape)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "vocab_size = df['old_problem_id'].nunique() + 1 # Number of unique problem IDs\n",
    "print(vocab_size)\n",
    "\n",
    "df = df[['user_xid', 'old_problem_id', 'skill_id', 'discrete_score', 'start_time']]\n",
    "df = df.sort_values(by=['user_xid', 'start_time'])\n",
    "df = df.fillna(0)  # Fill missing values with 0 for now\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['encoded_problem_id'] = le.fit_transform(df['old_problem_id']) # Shift by 1 to reserve 0 for padding\n",
    "\n",
    "# Data Preprocessing\n",
    "grouped = df.groupby('user_xid')\n",
    "\n",
    "seq = []\n",
    "lab = []\n",
    "for user, group in grouped:\n",
    "    group = group.sort_values(by='start_time')\n",
    "    feature_seq = group['encoded_problem_id'].to_numpy()\n",
    "    seq.append(torch.tensor(feature_seq, dtype=torch.float32))\n",
    "    \n",
    "    blank_labels = np.full((group.shape[1], vocab_size), -1)\n",
    "    print(blank_labels)\n",
    "\n",
    "    # Ensure labels are treated as a tensor\n",
    "    labels = torch.tensor(group['discrete_score'].to_numpy(), dtype=torch.float32)\n",
    "    lab.append(labels)\n",
    "\n",
    "# Padding sequences with zeros using PyTorch's pad_sequence\n",
    "padded_seq = pad_sequence(seq, batch_first=True, padding_value=0)  # (batch_size, timesteps)\n",
    "padded_lab = pad_sequence(lab, batch_first=True, padding_value=0.0)  # (batch_size, timesteps)\n",
    "\n",
    "# Reshape labels to have 3D shape (batch_size, timesteps, 1)\n",
    "padded_lab = padded_lab.unsqueeze(-1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print(padded_seq.shape)\n",
    "print(padded_lab.shape)\n",
    "y = np.squeeze(padded_lab)\n",
    "print(y)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "source": [
    "# Split data into training and testing\n",
    "X_train, X_test = train_test_split(seq, test_size=0.2, random_state=200)\n",
    "y_train, y_test = train_test_split(lab, test_size=0.2, random_state=200)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "VOCAB_SIZE = df['old_problem_id'].nunique() + 1\n",
    "print(VOCAB_SIZE)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "source": [
    "# Model Instantiation\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=numDim, mask_zero=True, input_length=None))\n",
    "model.add(LSTM(64, activation='tanh', return_sequences=True))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', 'AUC'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Training\n",
    "model.fit(X_train, y_train, \n",
    "         validation_data=(X_train, y_train),\n",
    "         epochs=1, \n",
    "         batch_size=32)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Evaluate Model on Test Data\n",
    "model.evaluate(X_test, y_test)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Predict on Test Data\n",
    "model.predict(X_test)"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
