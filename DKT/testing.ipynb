{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T15:44:50.255589Z",
     "start_time": "2024-10-03T15:44:42.078099Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding, TimeDistributed, Masking, StringLookup\n",
    "from keras.layers import Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import keras"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T15:44:52.116318Z",
     "start_time": "2024-10-03T15:44:50.258127Z"
    }
   },
   "source": [
    "df = pd.read_csv('../Data/non_skill_builder_data_new.csv') # fill with data file\n",
    "data = df.sample(frac=0.05, random_state=69)"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T15:44:52.147316Z",
     "start_time": "2024-10-03T15:44:52.118602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = data[['user_id', 'problem_id', 'skill_id', 'correct', 'order_id']]\n",
    "data = data.sort_values(by=['user_id', 'order_id'])\n",
    "data = data.fillna(0)  # Fill missing values with 0 for now"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T15:44:52.164819Z",
     "start_time": "2024-10-03T15:44:52.149953Z"
    }
   },
   "cell_type": "code",
   "source": [
    "un = data['problem_id'].astype(str).unique()\n",
    "zer = un + '+0'\n",
    "on = un + '+1'"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T15:44:52.172897Z",
     "start_time": "2024-10-03T15:44:52.168658Z"
    }
   },
   "cell_type": "code",
   "source": "vocab = np.concatenate([zer,on])",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T15:44:52.184377Z",
     "start_time": "2024-10-03T15:44:52.175239Z"
    }
   },
   "cell_type": "code",
   "source": "vocab",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T15:44:52.202413Z",
     "start_time": "2024-10-03T15:44:52.186740Z"
    }
   },
   "cell_type": "code",
   "source": "data['prob_id_x_correct'] = data['problem_id'].astype(str).copy()",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T15:44:52.211135Z",
     "start_time": "2024-10-03T15:44:52.204453Z"
    }
   },
   "cell_type": "code",
   "source": "data['prob_id_x_correct']",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T15:44:52.218366Z",
     "start_time": "2024-10-03T15:44:52.213667Z"
    }
   },
   "cell_type": "code",
   "source": "data.reset_index(inplace=True)",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T15:44:52.236954Z",
     "start_time": "2024-10-03T15:44:52.220607Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data.loc[data['correct'] == 0, 'prob_id_x_correct'] += '+0'\n",
    "data.loc[data['correct'] == 1, 'prob_id_x_correct'] += '+1'"
   ],
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T15:44:57.348453Z",
     "start_time": "2024-10-03T15:44:52.239088Z"
    }
   },
   "source": [
    "vocab_size = len(vocab) + 2  # Number of unique problem IDs\n",
    "max_seq_len = 10  # Set maximum sequence length\n",
    "numDim = math.ceil(math.log(vocab_size)) # Number of dimensions for embedding layer\n",
    "\n",
    "labelEnc = StringLookup(vocabulary=vocab, output_mode='int', mask_token='na')\n",
    "data['encoded_problem_id'] = labelEnc(data['prob_id_x_correct'])\n",
    "\n",
    "grouped = data.groupby('user_id')\n",
    "\n",
    "seq = []\n",
    "lab = []\n",
    "\n",
    "\n",
    "for user, group in tqdm(grouped):\n",
    "    group = group.sort_values(by='order_id')\n",
    "    feature_seq = group['encoded_problem_id'].to_numpy()\n",
    "    correct_seq = group['correct'].to_numpy()\n",
    "    \n",
    "    \n",
    "\n",
    "    for start_idx in range(0, len(feature_seq), max_seq_len):\n",
    "        end_idx = min(start_idx + max_seq_len, len(feature_seq))\n",
    "\n",
    "        # Get subsequence for this user\n",
    "        sub_feature_seq = feature_seq[start_idx:end_idx]\n",
    "        sub_correct_seq = correct_seq[start_idx:end_idx]\n",
    "\n",
    "        # Pad feature sequence to max_seq_len\n",
    "        padded_feature_seq = F.pad(torch.tensor(sub_feature_seq, dtype=torch.float32),\n",
    "                                   (0, max_seq_len - len(sub_feature_seq)),\n",
    "                                   value=0)\n",
    "        seq.append(padded_feature_seq)\n",
    "\n",
    "        # Pad label sequence with shape [timesteps, vocab_size]\n",
    "        blank_labels = np.full((max_seq_len, vocab_size), -1, dtype=np.float32)\n",
    "        blank_labels[:len(sub_feature_seq), sub_feature_seq] = sub_correct_seq\n",
    "\n",
    "        lab.append(torch.tensor(blank_labels, dtype=torch.float32))\n",
    "\n",
    "# Convert seq and lab to tensors\n",
    "seq = torch.stack(seq)\n",
    "lab = torch.stack(lab)"
   ],
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T15:44:57.356180Z",
     "start_time": "2024-10-03T15:44:57.350624Z"
    }
   },
   "source": [
    "data.shape"
   ],
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T15:44:57.362403Z",
     "start_time": "2024-10-03T15:44:57.357886Z"
    }
   },
   "source": [
    "print(seq.shape)\n",
    "print(lab.shape)\n",
    "print(vocab_size)\n",
    "print(numDim)"
   ],
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T15:44:57.738703Z",
     "start_time": "2024-10-03T15:44:57.365485Z"
    }
   },
   "source": [
    "# Split data into training and testing\n",
    "X_train, X_test = train_test_split(seq, test_size=0.2, random_state=200)\n",
    "y_train, y_test = train_test_split(lab, test_size=0.2, random_state=200)"
   ],
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T15:44:57.746077Z",
     "start_time": "2024-10-03T15:44:57.740562Z"
    }
   },
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ],
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T15:44:57.754178Z",
     "start_time": "2024-10-03T15:44:57.748626Z"
    }
   },
   "source": [
    "y_train.shape"
   ],
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T15:44:57.761419Z",
     "start_time": "2024-10-03T15:44:57.756373Z"
    }
   },
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "   indices = tf.math.not_equal(y_true, -1)\n",
    "   y_true_rel =y_true[indices]\n",
    "   y_pred_rel = y_pred[indices]\n",
    "   return tf.keras.losses.binary_crossentropy(y_true_rel, y_pred_rel)"
   ],
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T15:44:57.790553Z",
     "start_time": "2024-10-03T15:44:57.763613Z"
    }
   },
   "source": [
    "# Model Instantiation\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=numDim, input_length=None, mask_zero=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(124, activation='tanh', return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(vocab_size, activation='sigmoid')))\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              loss=custom_loss,\n",
    "              metrics=['accuracy', 'AUC'])"
   ],
   "execution_count": 18,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T15:47:48.387273Z",
     "start_time": "2024-10-03T15:47:48.377181Z"
    }
   },
   "cell_type": "code",
   "source": "y_traina",
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T15:47:26.352722Z",
     "start_time": "2024-10-03T15:47:26.226172Z"
    }
   },
   "source": [
    "# Training\n",
    "model.fit(x=X_train, y=y_train, \n",
    "         epochs=10, \n",
    "         batch_size=32)"
   ],
   "execution_count": 21,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
