{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T15:44:50.255589Z",
     "start_time": "2024-10-03T15:44:42.078099Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding, TimeDistributed, Masking, StringLookup\n",
    "from keras.layers import Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import keras"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-03 11:44:43.296802: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-03 11:44:43.410541: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-03 11:44:43.442952: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-03 11:44:43.674914: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-03 11:44:45.302661: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T15:44:52.116318Z",
     "start_time": "2024-10-03T15:44:50.258127Z"
    }
   },
   "source": [
    "df = pd.read_csv('../Data/non_skill_builder_data_new.csv') # fill with data file\n",
    "data = df.sample(frac=0.05, random_state=69)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T15:44:52.147316Z",
     "start_time": "2024-10-03T15:44:52.118602Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = data[['user_id', 'problem_id', 'skill_id', 'correct', 'order_id']]\n",
    "data = data.sort_values(by=['user_id', 'order_id'])\n",
    "data = data.fillna(0)  # Fill missing values with 0 for now"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T15:44:52.164819Z",
     "start_time": "2024-10-03T15:44:52.149953Z"
    }
   },
   "cell_type": "code",
   "source": [
    "un = data['problem_id'].astype(str).unique()\n",
    "zer = un + '+0'\n",
    "on = un + '+1'"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T15:44:52.172897Z",
     "start_time": "2024-10-03T15:44:52.168658Z"
    }
   },
   "cell_type": "code",
   "source": "vocab = np.concatenate([zer,on])",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T15:44:52.184377Z",
     "start_time": "2024-10-03T15:44:52.175239Z"
    }
   },
   "cell_type": "code",
   "source": "vocab",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['84895+0', '86314+0', '39460+0', ..., '110879+1', '110146+1',\n",
       "       '110505+1'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T15:44:52.202413Z",
     "start_time": "2024-10-03T15:44:52.186740Z"
    }
   },
   "cell_type": "code",
   "source": "data['prob_id_x_correct'] = data['problem_id'].astype(str).copy()",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T15:44:52.211135Z",
     "start_time": "2024-10-03T15:44:52.204453Z"
    }
   },
   "cell_type": "code",
   "source": "data['prob_id_x_correct']",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "496319    84895\n",
       "496336    86314\n",
       "496353    39460\n",
       "496361    97776\n",
       "496380    54003\n",
       "          ...  \n",
       "588216    83653\n",
       "588217    83658\n",
       "588232    39681\n",
       "588243    39475\n",
       "588263    39774\n",
       "Name: prob_id_x_correct, Length: 30156, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T15:44:52.218366Z",
     "start_time": "2024-10-03T15:44:52.213667Z"
    }
   },
   "cell_type": "code",
   "source": "data.reset_index(inplace=True)",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T15:44:52.236954Z",
     "start_time": "2024-10-03T15:44:52.220607Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data.loc[data['correct'] == 0, 'prob_id_x_correct'] += '+0'\n",
    "data.loc[data['correct'] == 1, 'prob_id_x_correct'] += '+1'"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T15:44:57.348453Z",
     "start_time": "2024-10-03T15:44:52.239088Z"
    }
   },
   "source": [
    "vocab_size = len(vocab) + 2  # Number of unique problem IDs\n",
    "max_seq_len = 10  # Set maximum sequence length\n",
    "numDim = math.ceil(math.log(vocab_size)) # Number of dimensions for embedding layer\n",
    "\n",
    "labelEnc = StringLookup(vocabulary=vocab, output_mode='int', mask_token='na')\n",
    "data['encoded_problem_id'] = labelEnc(data['prob_id_x_correct'])\n",
    "\n",
    "grouped = data.groupby('user_id')\n",
    "\n",
    "seq = []\n",
    "lab = []\n",
    "\n",
    "\n",
    "for user, group in tqdm(grouped):\n",
    "    group = group.sort_values(by='order_id')\n",
    "    feature_seq = group['encoded_problem_id'].to_numpy()\n",
    "    correct_seq = group['correct'].to_numpy()\n",
    "    \n",
    "    \n",
    "\n",
    "    for start_idx in range(0, len(feature_seq), max_seq_len):\n",
    "        end_idx = min(start_idx + max_seq_len, len(feature_seq))\n",
    "\n",
    "        # Get subsequence for this user\n",
    "        sub_feature_seq = feature_seq[start_idx:end_idx]\n",
    "        sub_correct_seq = correct_seq[start_idx:end_idx]\n",
    "\n",
    "        # Pad feature sequence to max_seq_len\n",
    "        padded_feature_seq = F.pad(torch.tensor(sub_feature_seq, dtype=torch.float32),\n",
    "                                   (0, max_seq_len - len(sub_feature_seq)),\n",
    "                                   value=0)\n",
    "        seq.append(padded_feature_seq)\n",
    "\n",
    "        # Pad label sequence with shape [timesteps, vocab_size]\n",
    "        blank_labels = np.full((max_seq_len, vocab_size), -1, dtype=np.float32)\n",
    "        blank_labels[:len(sub_feature_seq), sub_feature_seq] = sub_correct_seq\n",
    "\n",
    "        lab.append(torch.tensor(blank_labels, dtype=torch.float32))\n",
    "\n",
    "# Convert seq and lab to tensors\n",
    "seq = torch.stack(seq)\n",
    "lab = torch.stack(lab)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1727970292.609211    8635 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-03 11:44:52.616236: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "100%|██████████| 5553/5553 [00:03<00:00, 1472.88it/s]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T15:44:57.356180Z",
     "start_time": "2024-10-03T15:44:57.350624Z"
    }
   },
   "source": [
    "data.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30156, 8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T15:44:57.362403Z",
     "start_time": "2024-10-03T15:44:57.357886Z"
    }
   },
   "source": [
    "print(seq.shape)\n",
    "print(lab.shape)\n",
    "print(vocab_size)\n",
    "print(numDim)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6682, 10])\n",
      "torch.Size([6682, 10, 7394])\n",
      "7394\n",
      "9\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T15:44:57.738703Z",
     "start_time": "2024-10-03T15:44:57.365485Z"
    }
   },
   "source": [
    "# Split data into training and testing\n",
    "X_train, X_test = train_test_split(seq, test_size=0.2, random_state=200)\n",
    "y_train, y_test = train_test_split(lab, test_size=0.2, random_state=200)"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T15:44:57.746077Z",
     "start_time": "2024-10-03T15:44:57.740562Z"
    }
   },
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5345, 10])\n",
      "torch.Size([5345, 10, 7394])\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T15:44:57.754178Z",
     "start_time": "2024-10-03T15:44:57.748626Z"
    }
   },
   "source": [
    "y_train.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5345, 10, 7394])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T15:44:57.761419Z",
     "start_time": "2024-10-03T15:44:57.756373Z"
    }
   },
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "   indices = tf.math.not_equal(y_true, -1)\n",
    "   y_true_rel =y_true[indices]\n",
    "   y_pred_rel = y_pred[indices]\n",
    "   return tf.keras.losses.binary_crossentropy(y_true_rel, y_pred_rel)"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T15:44:57.790553Z",
     "start_time": "2024-10-03T15:44:57.763613Z"
    }
   },
   "source": [
    "# Model Instantiation\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=numDim, input_length=None, mask_zero=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(124, activation='tanh', return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(vocab_size, activation='sigmoid')))\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              loss=custom_loss,\n",
    "              metrics=['accuracy', 'AUC'])"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T15:47:48.387273Z",
     "start_time": "2024-10-03T15:47:48.377181Z"
    }
   },
   "cell_type": "code",
   "source": "y_traina",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         ...,\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       "\n",
       "        [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         ...,\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       "\n",
       "        [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         ...,\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         ...,\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       "\n",
       "        [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         ...,\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
       "\n",
       "        [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         ...,\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.],\n",
       "         [-1., -1., -1.,  ..., -1., -1., -1.]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T15:47:26.352722Z",
     "start_time": "2024-10-03T15:47:26.226172Z"
    }
   },
   "source": [
    "# Training\n",
    "model.fit(x=X_train, y=y_train, \n",
    "         epochs=10, \n",
    "         batch_size=32)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[21], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Training\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m         \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m10\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m         \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m32\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/python-envs/HW3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m    120\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m    121\u001B[0m     \u001B[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m--> 122\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    123\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    124\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/python-envs/HW3/lib/python3.10/site-packages/keras/src/trainers/trainer.py:923\u001B[0m, in \u001B[0;36mTrainer._pythonify_logs\u001B[0;34m(self, logs)\u001B[0m\n\u001B[1;32m    921\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_pythonify_logs\u001B[39m(\u001B[38;5;28mself\u001B[39m, logs):\n\u001B[1;32m    922\u001B[0m     result \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m--> 923\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m key, value \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28msorted\u001B[39m(\u001B[43mlogs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitems\u001B[49m()):\n\u001B[1;32m    924\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(value, \u001B[38;5;28mdict\u001B[39m):\n\u001B[1;32m    925\u001B[0m             result\u001B[38;5;241m.\u001B[39mupdate(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pythonify_logs(value))\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'items'"
     ]
    }
   ],
   "execution_count": 21
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
